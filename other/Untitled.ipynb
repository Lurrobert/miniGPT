 {
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fIg5j8nwSKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d5e5f1e-5147-4fd9-b5e5-a380d2bcfef9"
      },
      "source": [
        "!git clone https://github.com/karpathy/minGPT.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'minGPT' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWH9KXePtZ89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3339827-51da-49db-f847-accdbc53e1ed"
      },
      "source": [
        "%cd minGPT"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/minGPT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NVSQpPfrcmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mingpt.utils import set_seed\n",
        "set_seed(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UuvicHTrcmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGpKdwASrcmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, block_size):\n",
        "        chars = list(set(data))\n",
        "        data_size, vocab_size = len(data), len(chars)\n",
        "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "        \n",
        "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
        "        self.block_size = block_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.data) / (self.block_size + 1))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # we're actually going to \"cheat\" and pick a spot in the dataset at random\n",
        "        i = np.random.randint(0, len(self.data) - (self.block_size + 1))\n",
        "        chunk = self.data[i:i+self.block_size+1]\n",
        "        dix = [self.stoi[s] for s in chunk]\n",
        "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
        "        return x, y"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPIpZsc0rcmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "block_size = 128 # spatial extent of the model for its context"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI72vhFWxlCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "11035a2b-134b-4854-f620-8ac67f96ef50"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-24 11:21:40--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-09-24 11:21:40 (24.1 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz4b9m8grcml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5017b14f-ce20-4320-b22c-86c7f2efdcbd"
      },
      "source": [
        "text = open('input.txt', 'r').read() # don't worry we won't run out of file handles\n",
        "train_dataset = CharDataset(text, block_size)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data has 1115394 characters, 65 unique.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSp-UJKUrcmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbbcfd85-7cf5-454c-eaf8-6fa8edb6124c"
      },
      "source": [
        "from mingpt.model import GPT, GPTConfig\n",
        "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
        "                  n_layer=8, n_head=8, n_embd=512)\n",
        "model = GPT(mconf)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "09/24/2020 11:21:42 - INFO - mingpt.model -   number of parameters: 2.535219e+07\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByNsWd8kyGhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6b79ce8-0255-4acc-9f2a-c33da83da75c"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKau34n2rcms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4187e0de-1b21-4e01-8d72-ed432e8bb307"
      },
      "source": [
        "from mingpt.trainer import Trainer, TrainerConfig\n",
        "\n",
        "# initialize a trainer instance and kick off training\n",
        "tconf = TrainerConfig(max_epochs=3, batch_size=256, learning_rate=6e-4,\n",
        "                      lr_decay=True, warmup_tokens=512*20, final_tokens=200*len(train_dataset)*block_size,\n",
        "                      num_workers=4)\n",
        "trainer = Trainer(model, train_dataset, None, tconf)\n",
        "trainer.train()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 0: train loss 4.34087. lr 6.000000e-04:   0%|          | 0/34 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 0: train loss 4.34087. lr 6.000000e-04:   3%|▎         | 1/34 [00:02<01:07,  2.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 1: train loss 3.70672. lr 5.999999e-04:   3%|▎         | 1/34 [00:04<01:07,  2.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 1: train loss 3.70672. lr 5.999999e-04:   6%|▌         | 2/34 [00:04<01:04,  2.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 2: train loss 5.52498. lr 5.999998e-04:   6%|▌         | 2/34 [00:06<01:04,  2.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 2: train loss 5.52498. lr 5.999998e-04:   9%|▉         | 3/34 [00:06<01:02,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 3: train loss 4.34438. lr 5.999996e-04:   9%|▉         | 3/34 [00:08<01:02,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 3: train loss 4.34438. lr 5.999996e-04:  12%|█▏        | 4/34 [00:08<01:00,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 4: train loss 3.95912. lr 5.999993e-04:  12%|█▏        | 4/34 [00:10<01:00,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 4: train loss 3.95912. lr 5.999993e-04:  15%|█▍        | 5/34 [00:10<00:58,  2.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 5: train loss 3.68595. lr 5.999990e-04:  15%|█▍        | 5/34 [00:12<00:58,  2.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 5: train loss 3.68595. lr 5.999990e-04:  18%|█▊        | 6/34 [00:12<00:56,  2.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 6: train loss 3.45134. lr 5.999985e-04:  18%|█▊        | 6/34 [00:14<00:56,  2.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 6: train loss 3.45134. lr 5.999985e-04:  21%|██        | 7/34 [00:14<00:55,  2.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 7: train loss 3.34612. lr 5.999981e-04:  21%|██        | 7/34 [00:16<00:55,  2.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 7: train loss 3.34612. lr 5.999981e-04:  24%|██▎       | 8/34 [00:16<00:53,  2.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 8: train loss 3.41810. lr 5.999976e-04:  24%|██▎       | 8/34 [00:18<00:53,  2.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 8: train loss 3.41810. lr 5.999976e-04:  26%|██▋       | 9/34 [00:18<00:51,  2.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 9: train loss 3.42413. lr 5.999970e-04:  26%|██▋       | 9/34 [00:20<00:51,  2.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 9: train loss 3.42413. lr 5.999970e-04:  29%|██▉       | 10/34 [00:20<00:50,  2.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 10: train loss 3.38740. lr 5.999963e-04:  29%|██▉       | 10/34 [00:22<00:50,  2.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 10: train loss 3.38740. lr 5.999963e-04:  32%|███▏      | 11/34 [00:22<00:48,  2.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 11: train loss 3.36414. lr 5.999956e-04:  32%|███▏      | 11/34 [00:24<00:48,  2.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 11: train loss 3.36414. lr 5.999956e-04:  35%|███▌      | 12/34 [00:24<00:46,  2.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 12: train loss 3.33767. lr 5.999948e-04:  35%|███▌      | 12/34 [00:26<00:46,  2.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 12: train loss 3.33767. lr 5.999948e-04:  38%|███▊      | 13/34 [00:26<00:44,  2.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 13: train loss 3.32290. lr 5.999939e-04:  38%|███▊      | 13/34 [00:28<00:44,  2.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 13: train loss 3.32290. lr 5.999939e-04:  41%|████      | 14/34 [00:28<00:42,  2.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 14: train loss 3.31417. lr 5.999930e-04:  41%|████      | 14/34 [00:31<00:42,  2.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 14: train loss 3.31417. lr 5.999930e-04:  44%|████▍     | 15/34 [00:31<00:39,  2.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 15: train loss 3.31299. lr 5.999920e-04:  44%|████▍     | 15/34 [00:33<00:39,  2.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 15: train loss 3.31299. lr 5.999920e-04:  47%|████▋     | 16/34 [00:33<00:37,  2.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 16: train loss 3.32952. lr 5.999910e-04:  47%|████▋     | 16/34 [00:35<00:37,  2.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 16: train loss 3.32952. lr 5.999910e-04:  50%|█████     | 17/34 [00:35<00:35,  2.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 17: train loss 3.31789. lr 5.999899e-04:  50%|█████     | 17/34 [00:37<00:35,  2.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 17: train loss 3.31789. lr 5.999899e-04:  53%|█████▎    | 18/34 [00:37<00:32,  2.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 18: train loss 3.30167. lr 5.999887e-04:  53%|█████▎    | 18/34 [00:39<00:32,  2.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 18: train loss 3.30167. lr 5.999887e-04:  56%|█████▌    | 19/34 [00:39<00:30,  2.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 19: train loss 3.28545. lr 5.999874e-04:  56%|█████▌    | 19/34 [00:41<00:30,  2.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 19: train loss 3.28545. lr 5.999874e-04:  59%|█████▉    | 20/34 [00:41<00:28,  2.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 20: train loss 3.26349. lr 5.999861e-04:  59%|█████▉    | 20/34 [00:43<00:28,  2.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 20: train loss 3.26349. lr 5.999861e-04:  62%|██████▏   | 21/34 [00:43<00:26,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 21: train loss 3.25666. lr 5.999847e-04:  62%|██████▏   | 21/34 [00:45<00:26,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 21: train loss 3.25666. lr 5.999847e-04:  65%|██████▍   | 22/34 [00:45<00:24,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 22: train loss 3.21733. lr 5.999833e-04:  65%|██████▍   | 22/34 [00:47<00:24,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 22: train loss 3.21733. lr 5.999833e-04:  68%|██████▊   | 23/34 [00:47<00:21,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 23: train loss 3.17778. lr 5.999818e-04:  68%|██████▊   | 23/34 [00:49<00:21,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 23: train loss 3.17778. lr 5.999818e-04:  71%|███████   | 24/34 [00:49<00:19,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 24: train loss 3.15241. lr 5.999802e-04:  71%|███████   | 24/34 [00:50<00:19,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 24: train loss 3.15241. lr 5.999802e-04:  74%|███████▎  | 25/34 [00:50<00:17,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 25: train loss 3.15167. lr 5.999786e-04:  74%|███████▎  | 25/34 [00:52<00:17,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 25: train loss 3.15167. lr 5.999786e-04:  76%|███████▋  | 26/34 [00:52<00:15,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 26: train loss 3.14635. lr 5.999769e-04:  76%|███████▋  | 26/34 [00:54<00:15,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 26: train loss 3.14635. lr 5.999769e-04:  79%|███████▉  | 27/34 [00:54<00:13,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 27: train loss 3.12293. lr 5.999751e-04:  79%|███████▉  | 27/34 [00:56<00:13,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 27: train loss 3.12293. lr 5.999751e-04:  82%|████████▏ | 28/34 [00:56<00:11,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 28: train loss 3.12613. lr 5.999733e-04:  82%|████████▏ | 28/34 [00:58<00:11,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 28: train loss 3.12613. lr 5.999733e-04:  85%|████████▌ | 29/34 [00:58<00:09,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 29: train loss 3.11596. lr 5.999714e-04:  85%|████████▌ | 29/34 [01:00<00:09,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 29: train loss 3.11596. lr 5.999714e-04:  88%|████████▊ | 30/34 [01:00<00:07,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 30: train loss 3.08825. lr 5.999694e-04:  88%|████████▊ | 30/34 [01:02<00:07,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 30: train loss 3.08825. lr 5.999694e-04:  91%|█████████ | 31/34 [01:02<00:05,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 31: train loss 3.06239. lr 5.999674e-04:  91%|█████████ | 31/34 [01:04<00:05,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 31: train loss 3.06239. lr 5.999674e-04:  94%|█████████▍| 32/34 [01:04<00:03,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 32: train loss 3.06639. lr 5.999653e-04:  94%|█████████▍| 32/34 [01:06<00:03,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 32: train loss 3.06639. lr 5.999653e-04:  97%|█████████▋| 33/34 [01:06<00:01,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 33: train loss 3.03407. lr 5.999637e-04:  97%|█████████▋| 33/34 [01:07<00:01,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 1 iter 33: train loss 3.03407. lr 5.999637e-04: 100%|██████████| 34/34 [01:08<00:00,  2.00s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 0: train loss 2.97950. lr 5.999615e-04:   0%|          | 0/34 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 0: train loss 2.97950. lr 5.999615e-04:   3%|▎         | 1/34 [00:01<01:04,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 1: train loss 2.94457. lr 5.999592e-04:   3%|▎         | 1/34 [00:03<01:04,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 1: train loss 2.94457. lr 5.999592e-04:   6%|▌         | 2/34 [00:03<01:02,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 2: train loss 2.90558. lr 5.999569e-04:   6%|▌         | 2/34 [00:05<01:02,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 2: train loss 2.90558. lr 5.999569e-04:   9%|▉         | 3/34 [00:05<01:00,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 3: train loss 2.86741. lr 5.999545e-04:   9%|▉         | 3/34 [00:07<01:00,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 3: train loss 2.86741. lr 5.999545e-04:  12%|█▏        | 4/34 [00:07<00:58,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 4: train loss 2.84558. lr 5.999520e-04:  12%|█▏        | 4/34 [00:09<00:58,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 4: train loss 2.84558. lr 5.999520e-04:  15%|█▍        | 5/34 [00:09<00:56,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 5: train loss 2.83535. lr 5.999495e-04:  15%|█▍        | 5/34 [00:11<00:56,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 5: train loss 2.83535. lr 5.999495e-04:  18%|█▊        | 6/34 [00:11<00:54,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 6: train loss 2.79245. lr 5.999469e-04:  18%|█▊        | 6/34 [00:13<00:54,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 6: train loss 2.79245. lr 5.999469e-04:  21%|██        | 7/34 [00:13<00:52,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 7: train loss 2.78051. lr 5.999442e-04:  21%|██        | 7/34 [00:15<00:52,  1.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 7: train loss 2.78051. lr 5.999442e-04:  24%|██▎       | 8/34 [00:15<00:50,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 8: train loss 2.76132. lr 5.999415e-04:  24%|██▎       | 8/34 [00:17<00:50,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 8: train loss 2.76132. lr 5.999415e-04:  26%|██▋       | 9/34 [00:17<00:48,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 9: train loss 2.74542. lr 5.999387e-04:  26%|██▋       | 9/34 [00:19<00:48,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 9: train loss 2.74542. lr 5.999387e-04:  29%|██▉       | 10/34 [00:19<00:47,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 10: train loss 2.72698. lr 5.999359e-04:  29%|██▉       | 10/34 [00:21<00:47,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 10: train loss 2.72698. lr 5.999359e-04:  32%|███▏      | 11/34 [00:21<00:45,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 11: train loss 2.71068. lr 5.999329e-04:  32%|███▏      | 11/34 [00:23<00:45,  1.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 11: train loss 2.71068. lr 5.999329e-04:  35%|███▌      | 12/34 [00:23<00:43,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 12: train loss 2.70390. lr 5.999300e-04:  35%|███▌      | 12/34 [00:25<00:43,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 12: train loss 2.70390. lr 5.999300e-04:  38%|███▊      | 13/34 [00:25<00:41,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 13: train loss 2.69357. lr 5.999269e-04:  38%|███▊      | 13/34 [00:27<00:41,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 13: train loss 2.69357. lr 5.999269e-04:  41%|████      | 14/34 [00:27<00:39,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 14: train loss 2.67668. lr 5.999238e-04:  41%|████      | 14/34 [00:29<00:39,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 14: train loss 2.67668. lr 5.999238e-04:  44%|████▍     | 15/34 [00:29<00:37,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 15: train loss 2.66101. lr 5.999206e-04:  44%|████▍     | 15/34 [00:31<00:37,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 15: train loss 2.66101. lr 5.999206e-04:  47%|████▋     | 16/34 [00:31<00:35,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 16: train loss 2.66909. lr 5.999174e-04:  47%|████▋     | 16/34 [00:33<00:35,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 16: train loss 2.66909. lr 5.999174e-04:  50%|█████     | 17/34 [00:33<00:33,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 17: train loss 2.65883. lr 5.999141e-04:  50%|█████     | 17/34 [00:35<00:33,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 17: train loss 2.65883. lr 5.999141e-04:  53%|█████▎    | 18/34 [00:35<00:31,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 18: train loss 2.64556. lr 5.999107e-04:  53%|█████▎    | 18/34 [00:37<00:31,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 18: train loss 2.64556. lr 5.999107e-04:  56%|█████▌    | 19/34 [00:37<00:30,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 19: train loss 2.63532. lr 5.999073e-04:  56%|█████▌    | 19/34 [00:39<00:30,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 19: train loss 2.63532. lr 5.999073e-04:  59%|█████▉    | 20/34 [00:39<00:28,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 20: train loss 2.63619. lr 5.999038e-04:  59%|█████▉    | 20/34 [00:41<00:28,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 20: train loss 2.63619. lr 5.999038e-04:  62%|██████▏   | 21/34 [00:41<00:26,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 21: train loss 2.62789. lr 5.999002e-04:  62%|██████▏   | 21/34 [00:43<00:26,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 21: train loss 2.62789. lr 5.999002e-04:  65%|██████▍   | 22/34 [00:43<00:24,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 22: train loss 2.61807. lr 5.998966e-04:  65%|██████▍   | 22/34 [00:45<00:24,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 22: train loss 2.61807. lr 5.998966e-04:  68%|██████▊   | 23/34 [00:45<00:22,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 23: train loss 2.61145. lr 5.998929e-04:  68%|██████▊   | 23/34 [00:47<00:22,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 23: train loss 2.61145. lr 5.998929e-04:  71%|███████   | 24/34 [00:47<00:20,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 24: train loss 2.60039. lr 5.998891e-04:  71%|███████   | 24/34 [00:49<00:20,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 24: train loss 2.60039. lr 5.998891e-04:  74%|███████▎  | 25/34 [00:49<00:18,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 25: train loss 2.59574. lr 5.998853e-04:  74%|███████▎  | 25/34 [00:51<00:18,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 25: train loss 2.59574. lr 5.998853e-04:  76%|███████▋  | 26/34 [00:51<00:16,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 26: train loss 2.58739. lr 5.998814e-04:  76%|███████▋  | 26/34 [00:53<00:16,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 26: train loss 2.58739. lr 5.998814e-04:  79%|███████▉  | 27/34 [00:53<00:14,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 27: train loss 2.58058. lr 5.998774e-04:  79%|███████▉  | 27/34 [00:55<00:14,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 27: train loss 2.58058. lr 5.998774e-04:  82%|████████▏ | 28/34 [00:55<00:12,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 28: train loss 2.58970. lr 5.998734e-04:  82%|████████▏ | 28/34 [00:57<00:12,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 28: train loss 2.58970. lr 5.998734e-04:  85%|████████▌ | 29/34 [00:57<00:10,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 29: train loss 2.58161. lr 5.998693e-04:  85%|████████▌ | 29/34 [00:59<00:10,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 29: train loss 2.58161. lr 5.998693e-04:  88%|████████▊ | 30/34 [00:59<00:08,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 30: train loss 2.57488. lr 5.998652e-04:  88%|████████▊ | 30/34 [01:01<00:08,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 30: train loss 2.57488. lr 5.998652e-04:  91%|█████████ | 31/34 [01:01<00:06,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 31: train loss 2.56826. lr 5.998610e-04:  91%|█████████ | 31/34 [01:03<00:06,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 31: train loss 2.56826. lr 5.998610e-04:  94%|█████████▍| 32/34 [01:03<00:04,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 32: train loss 2.58316. lr 5.998567e-04:  94%|█████████▍| 32/34 [01:05<00:04,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 32: train loss 2.58316. lr 5.998567e-04:  97%|█████████▋| 33/34 [01:05<00:02,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 33: train loss 2.57546. lr 5.998533e-04:  97%|█████████▋| 33/34 [01:07<00:02,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 2 iter 33: train loss 2.57546. lr 5.998533e-04: 100%|██████████| 34/34 [01:07<00:00,  1.98s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 0: train loss 2.57058. lr 5.998489e-04:   0%|          | 0/34 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 0: train loss 2.57058. lr 5.998489e-04:   3%|▎         | 1/34 [00:02<01:07,  2.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 1: train loss 2.56297. lr 5.998445e-04:   3%|▎         | 1/34 [00:04<01:07,  2.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 1: train loss 2.56297. lr 5.998445e-04:   6%|▌         | 2/34 [00:04<01:04,  2.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 2: train loss 2.55905. lr 5.998399e-04:   6%|▌         | 2/34 [00:06<01:04,  2.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 2: train loss 2.55905. lr 5.998399e-04:   9%|▉         | 3/34 [00:06<01:02,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 3: train loss 2.55090. lr 5.998354e-04:   9%|▉         | 3/34 [00:08<01:02,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 3: train loss 2.55090. lr 5.998354e-04:  12%|█▏        | 4/34 [00:08<01:00,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 4: train loss 2.55178. lr 5.998307e-04:  12%|█▏        | 4/34 [00:09<01:00,  2.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 4: train loss 2.55178. lr 5.998307e-04:  15%|█▍        | 5/34 [00:10<00:58,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 5: train loss 2.54358. lr 5.998260e-04:  15%|█▍        | 5/34 [00:11<00:58,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 5: train loss 2.54358. lr 5.998260e-04:  18%|█▊        | 6/34 [00:11<00:55,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 6: train loss 2.53542. lr 5.998212e-04:  18%|█▊        | 6/34 [00:13<00:55,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 6: train loss 2.53542. lr 5.998212e-04:  21%|██        | 7/34 [00:13<00:53,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 7: train loss 2.52757. lr 5.998163e-04:  21%|██        | 7/34 [00:15<00:53,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 7: train loss 2.52757. lr 5.998163e-04:  24%|██▎       | 8/34 [00:15<00:51,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 8: train loss 2.54561. lr 5.998114e-04:  24%|██▎       | 8/34 [00:17<00:51,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 8: train loss 2.54561. lr 5.998114e-04:  26%|██▋       | 9/34 [00:17<00:49,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 9: train loss 2.54002. lr 5.998065e-04:  26%|██▋       | 9/34 [00:19<00:49,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 9: train loss 2.54002. lr 5.998065e-04:  29%|██▉       | 10/34 [00:19<00:47,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 10: train loss 2.53475. lr 5.998014e-04:  29%|██▉       | 10/34 [00:21<00:47,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 10: train loss 2.53475. lr 5.998014e-04:  32%|███▏      | 11/34 [00:21<00:45,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 11: train loss 2.53172. lr 5.997963e-04:  32%|███▏      | 11/34 [00:23<00:45,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 11: train loss 2.53172. lr 5.997963e-04:  35%|███▌      | 12/34 [00:23<00:43,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 12: train loss 2.53211. lr 5.997911e-04:  35%|███▌      | 12/34 [00:25<00:43,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 12: train loss 2.53211. lr 5.997911e-04:  38%|███▊      | 13/34 [00:25<00:41,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 13: train loss 2.52858. lr 5.997859e-04:  38%|███▊      | 13/34 [00:27<00:41,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 13: train loss 2.52858. lr 5.997859e-04:  41%|████      | 14/34 [00:27<00:39,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 14: train loss 2.52014. lr 5.997806e-04:  41%|████      | 14/34 [00:29<00:39,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 14: train loss 2.52014. lr 5.997806e-04:  44%|████▍     | 15/34 [00:29<00:37,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 15: train loss 2.51391. lr 5.997752e-04:  44%|████▍     | 15/34 [00:31<00:37,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 15: train loss 2.51391. lr 5.997752e-04:  47%|████▋     | 16/34 [00:31<00:35,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 16: train loss 2.52765. lr 5.997698e-04:  47%|████▋     | 16/34 [00:33<00:35,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 16: train loss 2.52765. lr 5.997698e-04:  50%|█████     | 17/34 [00:33<00:33,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 17: train loss 2.52196. lr 5.997643e-04:  50%|█████     | 17/34 [00:35<00:33,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 17: train loss 2.52196. lr 5.997643e-04:  53%|█████▎    | 18/34 [00:35<00:31,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 18: train loss 2.51789. lr 5.997587e-04:  53%|█████▎    | 18/34 [00:37<00:31,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 18: train loss 2.51789. lr 5.997587e-04:  56%|█████▌    | 19/34 [00:37<00:29,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 19: train loss 2.50973. lr 5.997531e-04:  56%|█████▌    | 19/34 [00:39<00:29,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 19: train loss 2.50973. lr 5.997531e-04:  59%|█████▉    | 20/34 [00:39<00:27,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 20: train loss 2.51533. lr 5.997474e-04:  59%|█████▉    | 20/34 [00:41<00:27,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 20: train loss 2.51533. lr 5.997474e-04:  62%|██████▏   | 21/34 [00:41<00:25,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 21: train loss 2.51289. lr 5.997417e-04:  62%|██████▏   | 21/34 [00:43<00:25,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 21: train loss 2.51289. lr 5.997417e-04:  65%|██████▍   | 22/34 [00:43<00:23,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 22: train loss 2.50468. lr 5.997358e-04:  65%|██████▍   | 22/34 [00:45<00:23,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 22: train loss 2.50468. lr 5.997358e-04:  68%|██████▊   | 23/34 [00:45<00:21,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 23: train loss 2.49824. lr 5.997299e-04:  68%|██████▊   | 23/34 [00:47<00:21,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 23: train loss 2.49824. lr 5.997299e-04:  71%|███████   | 24/34 [00:47<00:19,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 24: train loss 2.49420. lr 5.997240e-04:  71%|███████   | 24/34 [00:49<00:19,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 24: train loss 2.49420. lr 5.997240e-04:  74%|███████▎  | 25/34 [00:49<00:17,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 25: train loss 2.48937. lr 5.997180e-04:  74%|███████▎  | 25/34 [00:51<00:17,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 25: train loss 2.48937. lr 5.997180e-04:  76%|███████▋  | 26/34 [00:51<00:15,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 26: train loss 2.48601. lr 5.997119e-04:  76%|███████▋  | 26/34 [00:53<00:15,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 26: train loss 2.48601. lr 5.997119e-04:  79%|███████▉  | 27/34 [00:53<00:13,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 27: train loss 2.47711. lr 5.997058e-04:  79%|███████▉  | 27/34 [00:55<00:13,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 27: train loss 2.47711. lr 5.997058e-04:  82%|████████▏ | 28/34 [00:55<00:11,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 28: train loss 2.49172. lr 5.996995e-04:  82%|████████▏ | 28/34 [00:57<00:11,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 28: train loss 2.49172. lr 5.996995e-04:  85%|████████▌ | 29/34 [00:57<00:09,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 29: train loss 2.48540. lr 5.996933e-04:  85%|████████▌ | 29/34 [00:59<00:09,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 29: train loss 2.48540. lr 5.996933e-04:  88%|████████▊ | 30/34 [00:59<00:07,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 30: train loss 2.48183. lr 5.996869e-04:  88%|████████▊ | 30/34 [01:01<00:07,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 30: train loss 2.48183. lr 5.996869e-04:  91%|█████████ | 31/34 [01:01<00:05,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 31: train loss 2.47789. lr 5.996805e-04:  91%|█████████ | 31/34 [01:03<00:05,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 31: train loss 2.47789. lr 5.996805e-04:  94%|█████████▍| 32/34 [01:03<00:03,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 32: train loss 2.51553. lr 5.996741e-04:  94%|█████████▍| 32/34 [01:05<00:03,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 32: train loss 2.51553. lr 5.996741e-04:  97%|█████████▋| 33/34 [01:05<00:01,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 33: train loss 2.52822. lr 5.996690e-04:  97%|█████████▋| 33/34 [01:06<00:01,  2.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "epoch 3 iter 33: train loss 2.52822. lr 5.996690e-04: 100%|██████████| 34/34 [01:07<00:00,  1.97s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArLBdUDK2Pl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "5e0e7fb3-1c9a-4260-a8a9-736b6685bee9"
      },
      "source": [
        "from mingpt.utils import sample\n",
        "\n",
        "context = \"O God, O God!\"\n",
        "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None,...].to(trainer.device)\n",
        "y = sample(model, x, 2000, temperature=1.0, sample=True, top_k=10)[0]\n",
        "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
        "print(completion)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O God, O God!\n",
            "AN:\n",
            "\n",
            "\n",
            "SINRE:IO:So mear t the s, f be avimithilath s thantes a be dinchis ssimas pe ho s sees s, d mordary.Soris sonthayoner mee sess asere sest doureseathe fouthomy,\n",
            "\n",
            "HUF:\n",
            "Hesurare hothicithom, higot te te mongheres sel wie he haithe foreleryoncon al steng ald:\n",
            "Ade mato hendelde,\n",
            "I th t thowhat f woworend sen, aleres, t soucerillerouthangha we hise, thy matrotansor thad ata s te w my.\n",
            "\n",
            "PRATTIO:\n",
            "\n",
            "\n",
            "PY:\n",
            "A: thathof aickindor me t terd is se t s ssulinof hat, wighathan,\n",
            "Pere massthethu the toth's t all as f bo faneasithie tsury be sudsuee, theathoue shisse methetind sir tand bersules wominghier th t herarstllstot sit phe wh ffr m ta halesurish o bis ou haritheere sthicon fus pang tho strerithentho bess serer or bouder s atherimie hendit thist hus he tat f wan thathiss ber s th,\n",
            "Fonce t th he o f s ancuse hit tos se f man wile t ain heris, her teesowhithe teanerthancldis toun t boutond d basstay.\n",
            "\n",
            "\n",
            "Mant fo wean hencasoullenthth winthistowhilld fistlanthordo honchosoryo shederig fais frifossere thoull mod pe as inthithediesond,\n",
            "Bod s mighe t bear t s, blataineerast trard sthe the t t the t w dimashara thortoresthalofresavea s ble, t del on,' d met, tend me w h avetan, minom be dore,\n",
            "Whe thile th ho fonton sore dnde he wo f ta this bere mithisen,\n",
            "Ar angeathe tal thindanda the s hig me mete, m'dand wayear tiere me atathandatourtstrerine w toda blounstet ba t hadstrenothe fartoudis the thed t buse\n",
            "Angharist higesurif mithin t he m, thisif thathie womes w berofote menor thunend t tiso do th thers se,\n",
            "Thounetho thans my avif dofo hifal houritoryotho ss wint s hereatildisthe the, hithe thy\n",
            "Plourothe tin s bancay therofod thisin t f taraserindofas ang su t w weratl trendimar se,\n",
            "Thithe p athinsure misino ber m dead o hisoder alor beere min fou toncend st moullalille the wousth s mou s thu mas, s bod sss a t doulofffis aneshous the f t,\n",
            "\n",
            "Andearig hoff ththaif berthilyon pe alorsurse thisto bt winouteree,\n",
            "An thth be an aveas we perear t, ply hy s ba arere mas wy thard pe ssssits b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOqx6fgk3tO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}